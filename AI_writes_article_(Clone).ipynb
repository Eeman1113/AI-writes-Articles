{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eeman1113/AI-writes-Articles/blob/main/AI_writes_article_(Clone).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run Only once "
      ],
      "metadata": {
        "id": "_htIXlpL-Hj5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpFCFs7-ihVX",
        "outputId": "495f071f-9d75-4672-a7a2-010b0fa70ea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Aug 18 13:13:18 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_yCw7BJnOaf"
      },
      "source": [
        "####**Installing HuggingFace Library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UzBTdycfTrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d3dbf2-0fd8-4ed4-bbaa-6a0eee5222ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GY8Cx1qnUDf"
      },
      "source": [
        "####**Importing the Library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_UcByaUfW80"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgulepwcnX0R"
      },
      "source": [
        "####**Initiating the GPT-2 Tokenizer and GPT-2 Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UY4Su36fW5E"
      },
      "outputs": [],
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-large\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2-large\", pad_token_id=tokenizer.eos_token_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Repeated runs"
      ],
      "metadata": {
        "id": "O7Wu_0BC-NnB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqKAaqTAfW3X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b7b2bed-2331-49c5-ba96-1df514a4a562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic you want AI to answer: What is going to change in earth in a hundred years \n"
          ]
        }
      ],
      "source": [
        "a=input(\"Topic you want AI to answer: \")\n",
        "input_sentence =  a+\"?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4khq_zWmnks7"
      },
      "source": [
        "####**Tokenizing Input Sentence**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_KV1n7ufW1t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22408259-c2a6-4727-d1bd-91f4a4518a17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2061,  318, 1016,  284, 1487,  287, 4534,  287,  257, 3470,  812, 5633]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "input_ids = tokenizer.encode(input_sentence, return_tensors=\"pt\")\n",
        "input_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6xYHf8ZnoU_"
      },
      "source": [
        "####**Generating Our Output**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm2jSoTqfWx5"
      },
      "outputs": [],
      "source": [
        "output = model.generate(\n",
        "    input_ids,         \n",
        "    max_length=1000, \n",
        "    num_beams=3,\n",
        "    no_repeat_ngram_size=6,\n",
        "    early_stopping=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffHSOttsnsA_"
      },
      "source": [
        "####**Finally Decoding the Generated Output**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDYJOahykcpf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "18f3e068-6eec-4960-d451-d6890a55c36e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"What is going to change in earth in a hundred years? I don't know. I don't know what's going to happen. I don't know if it's going to be good or bad. I don't know. But I know it's going to change. And I know that it's going to change for the better. And I know that we're going to be better off for it. And I know that I'm going to be better off because of it. And I'm going to do everything I can to make sure that that happens.\\n\\nAnd I'm going to do it because I think it's the right thing to do. I think it's the moral thing to do. And I think it's the patriotic thing to do. And it's the right thing for our country. And I'm not going to let anybody tell me that it's not the right thing to do, and I'm not going to allow anybody to tell me that it's the wrong thing to do.\\n\\nI'm going to do it. I'm going to make it happen. I'm going to fight for it, and I'm going to make sure that it happens for the right reasons.\\n\\nAnd I want to thank you all for being here. I want to thank you for being here. And I want to thank my family. I want to thank my wife. I want to thank all of you for being here.\\n\\nThank you. Thank you very much. Thank you. Thank you.\\n\\n(APPLAUSE)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "tokenizer.decode(output[0], skip_special_tokens=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "AI_writes_article_(Clone).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}